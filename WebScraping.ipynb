{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAsqhCCHa6+lj+5Kkn2uOW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Supriya090/Knowledge-Graph-Task/blob/master/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping using Beautiful Soup"
      ],
      "metadata": {
        "id": "RjH188oiQUEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MpMwViJQP5Pe"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libaries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the csv file\n",
        "news_data_csv = open('news_data.csv', 'w')\n",
        "fieldnames = ['TITLE', 'CONTENT']\n",
        "writer = csv.DictWriter(news_data_csv, fieldnames=fieldnames)\n",
        "writer.writeheader()"
      ],
      "metadata": {
        "id": "P6spC8iMQXmY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the headings and content of article\n",
        "def get_content(url):\n",
        "  page = requests.get(url)\n",
        "  page_soup = BeautifulSoup(page.content, 'html.parser')     # parsing code in HTML\n",
        "\n",
        "  #finding the heading\n",
        "  news_title = page_soup.find_all('h1')\n",
        "  print(news_title[0].get_text())\n",
        "\n",
        "  #finding the content\n",
        "  article_text=''\n",
        "  news_content = page_soup.find('div', class_=\"post-content-wrap\").findAll('p')   #getting only the content of <p> tag\n",
        "  for element in news_content:\n",
        "    article_text += '\\n' + ''.join(element.findAll(text = True))\n",
        "  print(article_text)\n",
        "\n",
        "  #writing the title and content to CSV\n",
        "  writer.writerow({'TITLE':news_title[0].get_text(), 'CONTENT':article_text})"
      ],
      "metadata": {
        "id": "gXBZLUMIQb-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the headings of article\n",
        "def get_links(url):\n",
        "  page = requests.get(url)\n",
        "  page_soup = BeautifulSoup(page.content, 'html.parser')     # parsing code in HTML\n",
        "  news_headings = page_soup.find('div',class_=\"listical-news-big\").find_all('h2')\n",
        "  link_with_href = []\n",
        "  link_list = []\n",
        "  for heads in news_headings:\n",
        "    link_with_href.append(heads.find('a', href=True))\n",
        "    # print(link_with_href['href'])\n",
        "  #   link_with_href.append()\n",
        "  for i in range(20):\n",
        "    link_list.append(link_with_href[i]['href'])\n",
        "  return link_list"
      ],
      "metadata": {
        "id": "n3K05D8HQcnu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links = get_links(\"https://english.onlinekhabar.com/category/business\")\n",
        "for i in range(20):\n",
        "  get_content(links[i])\n",
        "\n",
        "news_data_csv.close()\n",
        "print(\"CSV has been generated\")"
      ],
      "metadata": {
        "id": "8IOcGSfBQenS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I4R9Y6ziQgGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}